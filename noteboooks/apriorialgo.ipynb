{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0e0e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets Found:\n",
      "A: 3 occurrences\n",
      "B: 2 occurrences\n",
      "C: 2 occurrences\n",
      "('A', 'C'): 2 occurrences\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# 1️⃣ Load Dataset\n",
    "data = pd.read_csv('/home/varun/Desktop/scratch/data.csv')\n",
    "\n",
    "# 2️⃣ Preprocess Data\n",
    "def preprocess_data(df):\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        record = [str(item) for item in row if item != 'Nan']\n",
    "        records.append(record)\n",
    "    return records\n",
    "\n",
    "records = preprocess_data(data)\n",
    "\n",
    "# 3️⃣ Generate Frequent 1-itemsets\n",
    "def get_frequent_1_itemsets(records, min_support_count):\n",
    "    items = [item for sublist in records for item in sublist]\n",
    "    item_counts = pd.Series(items).value_counts()\n",
    "\n",
    "    # Filter items by minimum support count\n",
    "    frequent_items = item_counts[item_counts >= min_support_count].to_dict()\n",
    "    return frequent_items\n",
    "\n",
    "# 4️⃣ Generate Candidate Itemsets\n",
    "def generate_candidates(prev_frequent_itemsets, k):\n",
    "    candidates = []\n",
    "    prev_items = list(prev_frequent_itemsets.keys())\n",
    "    for i in range(len(prev_items)):\n",
    "        for j in range(i + 1, len(prev_items)):\n",
    "            candidate = tuple(sorted(set(prev_items[i]).union(set(prev_items[j]))))\n",
    "            if len(candidate) == k:\n",
    "                candidates.append(candidate)\n",
    "    return candidates\n",
    "\n",
    "# 5️⃣ Calculate Support for Itemsets\n",
    "def calculate_support(candidates, records):\n",
    "    support_count = {candidate: 0 for candidate in candidates}\n",
    "    for record in records:\n",
    "        for candidate in candidates:\n",
    "            if set(candidate).issubset(set(record)):\n",
    "                support_count[candidate] += 1\n",
    "    return support_count\n",
    "\n",
    "# 6️⃣ Apriori Algorithm Implementation\n",
    "def apriori(records, min_support_count):\n",
    "    frequent_itemsets = {}\n",
    "    k = 1\n",
    "    current_frequent_itemsets = get_frequent_1_itemsets(records, min_support_count)\n",
    "    \n",
    "    while current_frequent_itemsets:\n",
    "        frequent_itemsets.update(current_frequent_itemsets)\n",
    "        candidates = generate_candidates(current_frequent_itemsets, k + 1)\n",
    "        support_count = calculate_support(candidates, records)\n",
    "\n",
    "        # Filter candidates by support threshold\n",
    "        current_frequent_itemsets = {itemset: count for itemset, count in support_count.items() if count >= min_support_count}\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "# 7️⃣ Run Apriori Algorithm\n",
    "min_support_count = 2\n",
    "frequent_itemsets = apriori(records, min_support_count)\n",
    "\n",
    "# 8️⃣ Display Results\n",
    "print(\"Frequent Itemsets Found:\")\n",
    "for itemset, count in frequent_itemsets.items():\n",
    "    print(f\"{itemset}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dc73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
